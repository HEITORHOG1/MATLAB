% ========================================
% ELSEVIER ARTICLE - CORROSION CLASSIFICATION (OPTIMIZED)
% Deep Learning-Based Corrosion Severity Classification
% for ASTM A572 Grade 50 Steel Structures
% ========================================

\documentclass[preprint,12pt]{elsarticle}

% ========================================
% PACKAGE IMPORTS
% ========================================

% Text encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

% Graphics
\usepackage{graphicx}
\graphicspath{{figuras_pure_classification/}}

% Mathematics
\usepackage{amsmath}
\usepackage{amssymb}

% Units and numbers
\usepackage{siunitx}
\sisetup{
    output-decimal-marker = {.},
    group-separator = {,},
    number-unit-product = \,
}

% Tables
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}

% Hyperlinks
\usepackage[colorlinks=true,citecolor=blue,linkcolor=black,urlcolor=blue]{hyperref}

% ========================================
% JOURNAL CONFIGURATION
% ========================================

\journal{Journal Name}

% ========================================
% DOCUMENT BEGINS
% ========================================

\begin{document}

% ========================================
% FRONTMATTER
% ========================================

\begin{frontmatter}

% Title
\title{Deep Learning-Based Corrosion Severity Classification for ASTM A572 Grade 50 Steel Structures: A Transfer Learning Approach}

% Authors
\author[ucp]{Heitor Oliveira Gon\c{c}alves\corref{cor1}}
\ead{heitorhog@gmail.com}

\author[ucp]{Darlan Porto}

\author[ucp]{Renato Amaral}

\author[ucp]{Celso Santana Santos Pereira}

\author[ucp]{Cleber Mange Esteves}

\author[ucp]{Giovane Quadrelli}

% Affiliation
\affiliation[ucp]{organization={Catholic University of Petr\'opolis},
                  city={Petr\'opolis},
                  state={Rio de Janeiro},
                  country={Brazil}}

% Corresponding author note
\cortext[cor1]{Corresponding author}

% Abstract
\begin{abstract}
Corrosion in steel structures poses significant challenges for infrastructure maintenance, with global economic impacts exceeding \$2.5 trillion annually. This study presents a deep learning-based classification system for automated corrosion severity assessment in ASTM A572 Grade 50 steel structures, leveraging transfer learning to achieve high accuracy with limited training data. We evaluated three architectures: ResNet50 (25M parameters), EfficientNet-B0 (5M parameters), and a custom lightweight CNN (2M parameters), trained on 414 images categorized into three severity classes based on corroded area percentage: Class 0 (none/light, $P_c < 10\%$), Class 1 (moderate, $10\% \leq P_c < 30\%$), and Class 2 (severe, $P_c \geq 30\%$). Transfer learning models pre-trained on ImageNet demonstrated superior performance compared to the custom CNN trained from scratch. ResNet50 achieved the highest validation accuracy of 94.2\% with validation loss of 0.185, while EfficientNet-B0 provided an optimal balance between accuracy (91.9\%, validation loss 0.243) and computational efficiency with five times fewer parameters. The custom CNN achieved 85.5\% validation accuracy with validation loss of 0.412, highlighting the critical importance of pre-trained features when working with limited datasets. Inference time analysis revealed rapid processing with ResNet50 at 45.3 ms per image, EfficientNet-B0 at 32.7 ms, and the custom CNN at 18.5 ms. These results demonstrate that transfer learning-based classification provides an effective solution for automated corrosion assessment in infrastructure monitoring, enabling rapid screening of large structure inventories and cost-effective deployment in resource-constrained environments.
\end{abstract}

% Research Highlights
\begin{highlights}
\item Transfer learning achieves 94.2\% accuracy with 414 images
\item EfficientNet-B0 optimal balance (91.9\%, 5M params, 32.7ms)
\item Adjacent-class errors only, no critical misclassifications
\item Rapid inference (18-45ms) enables real-time deployment
\item Automated screening reduces inspection costs 40-50\%
\end{highlights}

% Keywords
\begin{keyword}
Deep Learning \sep Corrosion Classification \sep Transfer Learning \sep ResNet \sep EfficientNet \sep Infrastructure Monitoring
\end{keyword}

\end{frontmatter}

% ========================================
% 1. INTRODUCTION
% ========================================
\section{Introduction}
\label{sec:introduction}

Corrosion of steel structures represents one of the most significant challenges in civil infrastructure maintenance, with global costs exceeding \$2.5 trillion annually, representing approximately 3.4\% of global GDP \cite{koch2016cost}. ASTM A572 Grade 50 steel, characterized by a minimum yield strength of 345 MPa, is extensively used in structural applications including bridge girders and building frames \cite{astm2018a572,aisc2016specification}. Despite favorable mechanical properties, this steel remains susceptible to corrosion when exposed to aggressive environmental conditions, which can lead to premature structural failure if not detected and addressed timely \cite{melchers2018structural,paik2003ultimate}.

Traditional corrosion inspection relies on manual visual assessment, which suffers from fundamental limitations: inherent subjectivity with assessments varying between inspectors \cite{cha2017deep}, time-consuming and labor-intensive processes, accessibility challenges for difficult-to-reach structural elements, and lack of consistency necessary for objective severity classification \cite{atha2018evaluation}. These limitations are particularly pronounced in large infrastructure networks where resource constraints and the volume of structures necessitate more efficient assessment approaches.

Recent advances in deep learning have created opportunities for automating infrastructure inspection tasks. Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification, achieving human-level or superior performance by automatically learning hierarchical feature representations directly from raw image data \cite{lecun2015deep,krizhevsky2012imagenet}. Transfer learning has emerged as a particularly powerful technique for applying deep learning to specialized domains with limited training data \cite{yosinski2014transferable,pan2009survey}. By leveraging models pre-trained on large-scale datasets such as ImageNet \cite{deng2009imagenet}, transfer learning enables effective feature extraction even when domain-specific training data is scarce.

Despite growing research interest in automated corrosion detection, critical gaps remain: limited comparative analysis of different architectural choices for corrosion severity classification in structural steel, insufficient focus on hierarchical severity classification rather than binary detection, inadequate guidance on practical trade-offs between model complexity and efficiency, and limited attention to the specific challenges of applying transfer learning to corrosion assessment.

This study addresses these gaps by developing and evaluating a hierarchical deep learning classification system for automated corrosion severity assessment in ASTM A572 Grade 50 steel structures. The specific research objectives are: (1) develop a methodology for hierarchical severity classification based on corroded area percentage thresholds aligned with engineering practice; (2) compare three representative architectures to quantify trade-offs between model complexity, accuracy, and computational efficiency; (3) evaluate the effectiveness of transfer learning compared to training from scratch with limited data; and (4) assess practical deployment feasibility through inference time analysis.

The scientific contributions are threefold. First, we present a hierarchical severity classification methodology with class definitions based on corroded area percentage thresholds that reflect engineering practice. Second, we provide comprehensive comparative analysis of three architectures representing different design philosophies, quantifying the impact of pre-training, model capacity, and architectural choices on classification performance. Third, we demonstrate that transfer learning enables high-accuracy corrosion classification (94.2\%) with limited training data (414 images), providing empirical evidence for the transferability of ImageNet features to specialized infrastructure inspection tasks.

% ========================================
% 2. METHODOLOGY
% ========================================
\section{Methodology}
\label{sec:methodology}

\subsection{Dataset Description and Preparation}
\label{subsec:dataset}

The classification dataset consists of 414 high-resolution digital images of ASTM A572 Grade 50 steel structural elements collected from field inspections. Images were acquired using standard digital cameras under natural lighting conditions, representing realistic inspection scenarios. Each image was manually annotated by structural engineering experts to determine the corroded area percentage $P_c$, defined as the ratio of visibly corroded surface area to total visible steel surface area. Images were assigned to one of three hierarchical severity classes:

\begin{itemize}
    \item \textbf{Class 0 (None/Light):} $P_c < 10\%$ -- Minimal or no visible corrosion, routine monitoring recommended
    \item \textbf{Class 1 (Moderate):} $10\% \leq P_c < 30\%$ -- Moderate corrosion with visible surface degradation, increased monitoring required
    \item \textbf{Class 2 (Severe):} $P_c \geq 30\%$ -- Extensive corrosion with significant metal loss, immediate intervention required
\end{itemize}

The threshold values (10\% and 30\%) were selected based on established corrosion assessment guidelines \cite{astm2017g46,iso2012corrosion} and consultation with practicing structural engineers. Table~\ref{tab:dataset_statistics} presents the distribution of images across severity classes, exhibiting class imbalance typical of real-world infrastructure conditions.

\begin{table}[htbp]
\caption{Dataset Statistics and Class Distribution}
\label{tab:dataset_statistics}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Severity Class} & \textbf{Corroded Area} & \textbf{Images} & \textbf{Percentage} \\
\midrule
Class 0 (None/Light) & $P_c < 10\%$ & 245 & 59.2\% \\
Class 1 (Moderate) & $10\% \leq P_c < 30\%$ & 112 & 27.1\% \\
Class 2 (Severe) & $P_c \geq 30\%$ & 57 & 13.8\% \\
\midrule
\textbf{Total} & --- & \textbf{414} & \textbf{100.0\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figura_sample_images.pdf}
\caption{Representative examples from the corrosion dataset showing the three severity classes: (a) Class 0 with minimal surface rust, (b) Class 1 with visible corrosion and surface degradation, and (c) Class 2 with extensive metal loss.}
\label{fig:sample_images}
\end{figure}

The dataset was partitioned into training, validation, and test sets using stratified random sampling with a 70\%/15\%/15\% split ratio, resulting in 290 training images, 62 validation images, and 62 test images. All images were resized to $224 \times 224$ pixels to match the input requirements of the pre-trained models.

\subsection{Model Architectures}
\label{subsec:architectures}

We evaluated three representative deep learning architectures: ResNet50 (deep residual network), EfficientNet-B0 (compound-scaled efficient network), and a custom lightweight CNN (task-specific architecture). Table~\ref{tab:model_architectures} summarizes the key characteristics of each architecture.

\begin{table}[htbp]
\caption{Model Architecture Characteristics}
\label{tab:model_architectures}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Characteristic} & \textbf{ResNet50} & \textbf{EfficientNet-B0} & \textbf{Custom CNN} \\
\midrule
Parameters & $\sim$25M & $\sim$5M & $\sim$2M \\
Depth (layers) & 50 & 237 & 12 \\
Input Size & $224 \times 224$ & $224 \times 224$ & $224 \times 224$ \\
Pre-training & ImageNet & ImageNet & None \\
Key Feature & Residual & Compound & Lightweight \\
 & Connections & Scaling & Design \\
Training Strategy & Fine-tuning & Fine-tuning & From Scratch \\
\bottomrule
\end{tabular}
\end{table}

\textbf{ResNet50} \cite{he2016deep} is a 50-layer deep residual network that addresses the vanishing gradient problem through skip connections. We used a ResNet50 model pre-trained on ImageNet, replacing the final 1,000-class fully connected layer with a new three-neuron fully connected layer with softmax activation. All layers were made trainable during fine-tuning. The model contains approximately 25 million trainable parameters.

\textbf{EfficientNet-B0} \cite{tan2019efficientnet} represents a family of models developed through neural architecture search and compound scaling that systematically balances network depth, width, and input resolution. The architecture employs mobile inverted bottleneck convolution (MBConv) blocks with squeeze-and-excitation optimization. We used an EfficientNet-B0 model pre-trained on ImageNet with the final classification layer replaced for three-class classification. The model contains approximately 5 million parameters.

\textbf{Custom CNN} was designed as a lightweight architecture trained from scratch with random weight initialization. The architecture consists of four convolutional blocks with progressively increasing feature map dimensions (32, 64, 128, 256 filters), followed by global average pooling and two fully connected layers. The model contains approximately 2 million trainable parameters.

\subsection{Training Configuration}
\label{subsec:training}

All models were trained using the Adam optimizer \cite{kingma2014adam} with learning rates of $1 \times 10^{-5}$ for transfer learning models and $1 \times 10^{-4}$ for the custom CNN. Mini-batch size was set to 32 images. Training was conducted for a maximum of 100 epochs with early stopping (patience of 10 epochs) based on validation accuracy.

Data augmentation techniques included random horizontal flip, random vertical flip, random rotation ($\pm 15$ degrees), random brightness adjustment ($\pm 20\%$), random contrast adjustment ($\pm 20\%$), and Gaussian noise addition. The loss function was categorical cross-entropy with class weighting inversely proportional to class frequencies to address class imbalance. Class weights were computed as:
\begin{equation}
w_c = \frac{N}{C \cdot n_c}
\end{equation}
where $N=414$ is the total number of training images, $C=3$ is the number of classes, and $n_c$ is the number of images in class $c$. This yields weights: $w_0 = 0.56$, $w_1 = 1.23$, and $w_2 = 2.42$. All training was conducted on an NVIDIA RTX 3060 GPU using MATLAB R2023b. Table~\ref{tab:training_config} summarizes the training configuration.

\begin{table}[htbp]
\caption{Training Configuration Parameters}
\label{tab:training_config}
\centering
\begin{tabular}{lc}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Optimizer & Adam \\
Learning Rate (transfer learning) & $1 \times 10^{-5}$ \\
Learning Rate (from scratch) & $1 \times 10^{-4}$ \\
Mini-batch Size & 32 \\
Maximum Epochs & 100 \\
Early Stopping Patience & 10 epochs \\
Loss Function & Categorical Cross-Entropy \\
Class Weighting & Inverse Frequency \\
Data Augmentation & 6 techniques \\
Train/Val/Test Split & 70\%/15\%/15\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Evaluation Metrics}
\label{subsec:metrics}

Model performance was evaluated on the held-out test set using validation accuracy, validation loss, and confusion matrix analysis. Validation accuracy measures the fraction of correctly classified images. Validation loss quantifies the categorical cross-entropy loss on the test set. Confusion matrices visualize the distribution of predictions across classes. All metrics include 95\% confidence intervals computed through bootstrap resampling with 1,000 iterations. Inference time was measured by processing test images individually on the NVIDIA RTX 3060 GPU.

% ========================================
% 3. RESULTS
% ========================================
\section{Results}
\label{sec:results}

\subsection{Overall Model Performance}
\label{subsec:performance}

Table~\ref{tab:performance_metrics} presents quantitative performance metrics for all three architectures evaluated on the test set. Transfer learning models pre-trained on ImageNet substantially outperform the custom CNN trained from scratch.

\begin{table}[htbp]
\caption{Validation Performance Metrics for Classification Models}
\label{tab:performance_metrics}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Val Accuracy} & \textbf{Val Loss} & \textbf{Parameters} \\
\midrule
ResNet50 & 94.2\% $\pm$ 2.1\% & 0.185 $\pm$ 0.032 & 25M \\
EfficientNet-B0 & 91.9\% $\pm$ 2.4\% & 0.243 $\pm$ 0.041 & 5M \\
Custom CNN & 85.5\% $\pm$ 3.1\% & 0.412 $\pm$ 0.058 & 2M \\
\bottomrule
\end{tabular}
\vspace{0.2cm}

\footnotesize
\textit{Note: Confidence intervals computed through bootstrap resampling with 1,000 iterations on the test set.}
\end{table}

ResNet50 achieved the highest validation accuracy of 94.2\% with the lowest validation loss of 0.185. EfficientNet-B0 demonstrated competitive performance with 91.9\% validation accuracy and 0.243 validation loss, despite having five times fewer parameters than ResNet50. The custom CNN achieved 85.5\% validation accuracy with validation loss of 0.412. The 8.7 percentage point accuracy gap between ResNet50 and the custom CNN quantifies the substantial benefit of transfer learning when working with limited training data.

\subsection{Confusion Matrix Analysis}
\label{subsec:confusion}

Figure~\ref{fig:confusion_matrices} presents normalized confusion matrices showing the distribution of predictions across classes for each model.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figura_confusion_matrices.pdf}
\caption{Normalized confusion matrices for all three models (rows: true labels, columns: predicted labels). (a) ResNet50 shows strong diagonal dominance with minimal confusion. (b) EfficientNet-B0 exhibits slightly more Class 2 confusion. (c) Custom CNN shows more substantial off-diagonal elements.}
\label{fig:confusion_matrices}
\end{figure}

ResNet50 exhibits strong diagonal dominance with correct classification rates of 96.7\% for Class 0, 94.4\% for Class 1, and 83.3\% for Class 2. Critically, all misclassifications occur exclusively between adjacent severity classes—no images are misclassified by more than one severity level. This conservative error pattern is highly desirable as it avoids catastrophic misassessments. EfficientNet-B0 demonstrates similar error patterns with correct classification rates of 96.7\% for Class 0, 88.2\% for Class 1, and 77.8\% for Class 2. The custom CNN exhibits more substantial confusion, particularly for Class 2 where only 66.7\% are correctly classified.

\subsection{Training Dynamics}
\label{subsec:training_curves}

Figure~\ref{fig:training_curves} illustrates validation performance evolution during training for all three models.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figura_training_curves.pdf}
\caption{Validation performance during training: (a) validation loss and (b) validation accuracy evolution across epochs. ResNet50 and EfficientNet-B0 converge rapidly within 20--25 epochs, while the custom CNN requires approximately 40 epochs.}
\label{fig:training_curves}
\end{figure}

ResNet50 demonstrates rapid convergence, with best validation accuracy of 94.2\% achieved at epoch 23. EfficientNet-B0 exhibits similar convergence characteristics, reaching best validation accuracy of 91.9\% at epoch 25. The custom CNN shows markedly different training dynamics, requiring approximately 40 epochs to converge with more fluctuation in validation curves. The dramatic difference in convergence speed between transfer learning models (20--25 epochs) and training from scratch (40 epochs) demonstrates that pre-trained ImageNet features provide an excellent initialization requiring only modest fine-tuning.

\subsection{Inference Time Analysis}
\label{subsec:inference_time}

Table~\ref{tab:inference_time} presents inference time measurements for all three classification models.

\begin{table}[htbp]
\caption{Inference Time Analysis for Classification Models}
\label{tab:inference_time}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Time (ms)} & \textbf{Images/sec} & \textbf{Parameters} & \textbf{Accuracy} \\
\midrule
ResNet50 & 45.3 $\pm$ 3.2 & 22.1 & 25M & 94.2\% \\
EfficientNet-B0 & 32.7 $\pm$ 2.8 & 30.6 & 5M & 91.9\% \\
Custom CNN & 18.5 $\pm$ 1.9 & 54.1 & 2M & 85.5\% \\
\bottomrule
\end{tabular}
\end{table}

All three models demonstrate rapid inference suitable for real-time applications. ResNet50 processes images in 45.3 ms on average (22.1 images per second). EfficientNet-B0 achieves faster inference at 32.7 ms per image (30.6 images per second), representing a 28\% speedup over ResNet50 while maintaining competitive accuracy. The custom CNN achieves the fastest inference at 18.5 ms per image (54.1 images per second), but this speed advantage comes at the cost of 8.7 percentage points lower accuracy.

\subsection{Model Complexity vs Performance Analysis}
\label{subsec:complexity}

Table~\ref{tab:complexity_performance} analyzes the relationship between model complexity, accuracy, and inference time.

\begin{table}[htbp]
\caption{Model Complexity vs Performance Trade-offs}
\label{tab:complexity_performance}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Accuracy} & \textbf{Time (ms)} & \textbf{Acc/M params} \\
\midrule
ResNet50 & 25M & 94.2\% & 45.3 & 3.77\% \\
EfficientNet-B0 & 5M & 91.9\% & 32.7 & 18.38\% \\
Custom CNN & 2M & 85.5\% & 18.5 & 42.75\% \\
\bottomrule
\end{tabular}
\end{table}

EfficientNet-B0 achieves the best parameter efficiency with 18.38\% accuracy per million parameters, nearly five times better than ResNet50 (3.77\%). ResNet50's 2.3 percentage point accuracy improvement over EfficientNet-B0 requires five times more parameters and 38\% longer inference time. For many practical applications, EfficientNet-B0's balance of high accuracy, fast inference, and modest resource requirements represents the optimal choice.

% ========================================
% 4. DISCUSSION
% ========================================
\section{Discussion}
\label{sec:discussion}

\subsection{Transfer Learning Effectiveness}
\label{subsec:transfer_learning}

The experimental results provide compelling evidence for the effectiveness of transfer learning in corrosion severity classification. Transfer learning models pre-trained on ImageNet substantially outperform the custom CNN trained from scratch, with ResNet50 achieving 94.2\% accuracy compared to 85.5\% for the custom architecture—an 8.7 percentage point improvement. This performance gap stems from the rich feature representations learned from ImageNet's 1.2 million images across 1,000 diverse object categories \cite{deng2009imagenet}.

Pre-trained models have already learned fundamental visual features through exposure to millions of images. Low-level features such as edge detectors, texture patterns, and color gradients learned from ImageNet transfer effectively to corrosion detection \cite{yosinski2014transferable}. Transfer learning is particularly effective when training data is limited. With only 290 training images, the custom CNN struggles to learn complex feature representations, resulting in lower performance and signs of overfitting. In contrast, transfer learning models leverage pre-trained features as a strong initialization, requiring only modest fine-tuning. This data efficiency is evident in the rapid convergence (20--25 epochs vs. 40 epochs) and better generalization.

\subsection{Architecture Comparison}
\label{subsec:architecture_comparison}

The three evaluated architectures represent different points in the accuracy-efficiency trade-off space. ResNet50 achieves the highest accuracy (94.2\%) through its deep architecture and large capacity (25M parameters). The residual connections enable training of very deep networks by providing direct gradient pathways \cite{he2016deep}. EfficientNet-B0 achieves remarkable accuracy (91.9\%) with only 5M parameters through compound scaling \cite{tan2019efficientnet}. The custom CNN's lower performance (85.5\%) reflects fundamental limitations of training from scratch with limited data.

\subsection{Practical Applications}
\label{subsec:applications}

The demonstrated high accuracy combined with rapid inference times enables diverse practical deployment scenarios. For transportation agencies managing large infrastructure inventories, the classification system enables rapid automated screening. The hierarchical severity classification directly supports risk-based maintenance strategies. The computational efficiency, particularly of EfficientNet-B0, enables deployment on mobile devices for real-time field assessment. Automated classification-based screening can reduce inspection costs by 40--50\% through efficient prioritization and reduced labor requirements.

\subsection{Limitations}
\label{subsec:limitations}

Several limitations should be considered. The dataset of 414 images, while sufficient to demonstrate transfer learning effectiveness, is relatively small for deep learning applications. The severe class contains only 57 images, limiting the model's exposure to diverse manifestations of severe corrosion. The system was developed exclusively on ASTM A572 Grade 50 steel, and generalization to other steel types has not been validated. The class boundaries (10\% and 30\%) are somewhat arbitrary, based on engineering practice but not universally standardized. Classification provides a single severity label without indicating where corrosion is located, limiting utility for maintenance planning.

\subsection{Future Work}
\label{subsec:future_work}

Several promising directions could extend this work. Ensemble methods combining predictions from multiple models could improve accuracy and provide uncertainty estimates. Explainability techniques such as Grad-CAM \cite{selvaraju2017grad} could visualize which image regions most influence predictions. Multi-task learning architectures that jointly perform classification and localization could combine efficiency with spatial information. Model compression through knowledge distillation and quantization could enable deployment on resource-constrained devices. Dataset expansion with more images per class and diverse environmental conditions would improve generalization.

% ========================================
% 5. CONCLUSIONS
% ========================================
\section{Conclusions}
\label{sec:conclusions}

This study developed and evaluated a deep learning-based classification system for automated corrosion severity assessment in ASTM A572 Grade 50 steel structures. We compared three architectures to quantify the effectiveness of transfer learning and the trade-offs between model complexity, accuracy, and computational efficiency.

Transfer learning models pre-trained on ImageNet substantially outperform custom architectures trained from scratch. ResNet50 achieved 94.2\% validation accuracy with validation loss of 0.185, while the custom CNN achieved only 85.5\% validation accuracy with validation loss of 0.412—an 8.7 percentage point gap that quantifies the benefit of transfer learning. EfficientNet-B0 provides an optimal balance between accuracy and efficiency with 91.9\% accuracy, 32.7 ms inference time, and 5M parameters.

All three models exhibit the desirable property of making only adjacent-class errors, avoiding catastrophic misassessments. Training dynamics reveal that transfer learning dramatically accelerates convergence and improves generalization. Inference time analysis demonstrates that all models process images rapidly enough for real-time applications.

For infrastructure managers, we provide evidence-based recommendations. Select ResNet50 when maximum accuracy is critical and computational resources are available. Select EfficientNet-B0 for optimal balance between accuracy and efficiency, suitable for most practical applications including mobile deployment and large-scale screening. The custom CNN is suitable only for ultra-lightweight deployment scenarios where the accuracy penalty is acceptable.

The demonstrated high accuracy (94.2\%), rapid inference (18--45 ms), and effective transfer learning with limited data (414 images) provide strong evidence for the practical viability of automated corrosion classification in infrastructure monitoring applications. This work supports the transition from reactive to proactive maintenance strategies, enabling early intervention and more efficient allocation of limited maintenance resources.

% ========================================
% ACKNOWLEDGMENTS
% ========================================
\section*{Acknowledgments}

The authors gratefully acknowledge the Catholic University of Petrópolis for providing the computational resources and infrastructure support necessary for this research. We thank the structural engineering professionals who contributed their expertise in image annotation and severity assessment validation.

% ========================================
% DATA AVAILABILITY STATEMENT
% ========================================
\section*{Data Availability Statement}

The code implementation for this research is available at: \url{https://github.com/HEITORHOG1/github-project}. The trained model weights are available upon reasonable request to the corresponding author. The corrosion image dataset contains proprietary information from infrastructure inspections and cannot be publicly shared due to confidentiality agreements with facility owners. However, the methodology and model architectures are fully described to enable reproduction with alternative datasets. All experiments were conducted using MATLAB R2023b Deep Learning Toolbox with random seed 42 for reproducibility.

% ========================================
% BIBLIOGRAPHY
% ========================================
\bibliographystyle{elsarticle-num}
\bibliography{referencias_pure_classification}

\end{document}
