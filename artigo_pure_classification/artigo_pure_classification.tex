\documentclass[Journal,letterpaper,InsideFigs]{ascelike-new}
\WarningFilter{caption}{Unknown document class}
\NameTag{Gon\c{c}alves, \today}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage{graphicx}
\graphicspath{{figuras_pure_classification/}}
\usepackage[style=base,figurename=Fig.,labelfont=bf,labelsep=period]{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{newtxtext,newtxmath}
\usepackage[colorlinks=true,citecolor=red,linkcolor=black,urlcolor=black]{hyperref}

\sisetup{
    output-decimal-marker = {.},
    group-separator = {,},
    number-unit-product = \ 
}

\title{DEEP LEARNING-BASED CORROSION SEVERITY CLASSIFICATION FOR ASTM A572 GRADE 50 STEEL STRUCTURES: A TRANSFER LEARNING APPROACH}

\author[1]{Heitor Oliveira Gon\c{c}alves}
\author[1]{Darlan Porto}
\author[1]{Renato Amaral}
\author[1]{Celso Santana Santos Pereira}
\author[1]{Cleber Mange Esteves}
\author[1]{Giovane Quadrelli}

\affil[1]{Catholic University of Petr\'opolis (UCP), Petr\'opolis, Rio de Janeiro, Brazil. \textit{Corresponding author}. Email: heitorhog@gmail.com}

\hypersetup{
    pdftitle={Deep Learning-Based Corrosion Severity Classification for ASTM A572 Grade 50 Steel Structures},
    pdfauthor={Heitor Oliveira Gon\c{c}alves, Darlan Porto, Renato Amaral, Celso Santana Santos Pereira, Cleber Mange Esteves, Giovane Quadrelli},
    pdfsubject={Deep Learning, Corrosion Classification, Transfer Learning},
    pdfkeywords={Deep Learning, Corrosion Classification, Transfer Learning, ASTM A572 Grade 50, ResNet, EfficientNet, Structural Inspection, Computer Vision, Infrastructure Monitoring}
}

\begin{document}

% ========================================
% TITLE PAGE
% ========================================
\maketitle

% ========================================
% ABSTRACT
% ========================================

\begin{abstract}
Corrosion in steel structures poses significant challenges for infrastructure maintenance, with global economic impacts exceeding \$2.5 trillion annually. Traditional manual inspection methods are subjective, time-consuming, and lack consistency, creating a critical need for automated assessment systems. This study presents a deep learning-based classification system for automated corrosion severity assessment in ASTM A572 Grade 50 steel structures, leveraging transfer learning to achieve high accuracy with limited training data. We evaluated three architectures: ResNet50 (25M parameters), EfficientNet-B0 (5M parameters), and a custom lightweight CNN (2M parameters), trained on a dataset of 414 images categorized into three severity classes based on corroded area percentage: Class 0 (none/light, $P_c < 10\%$), Class 1 (moderate, $10\% \leq P_c < 30\%$), and Class 2 (severe, $P_c \geq 30\%$). Transfer learning models pre-trained on ImageNet demonstrated superior performance compared to the custom CNN trained from scratch. ResNet50 achieved the highest validation accuracy of 94.2\% with validation loss of 0.185, while EfficientNet-B0 provided an optimal balance between accuracy (91.9\%, validation loss 0.243) and computational efficiency with five times fewer parameters. The custom CNN achieved 85.5\% validation accuracy with validation loss of 0.412, highlighting the critical importance of pre-trained features when working with limited datasets. Inference time analysis revealed that all classification models process images rapidly, with ResNet50 at 45.3 ms per image (22.1 images/second), EfficientNet-B0 at 32.7 ms (30.6 images/second), and the custom CNN at 18.5 ms (54.1 images/second). These results demonstrate that transfer learning-based classification provides an effective solution for automated corrosion assessment in infrastructure monitoring, enabling rapid screening of large structure inventories, real-time field assessment, and cost-effective deployment in resource-constrained environments. The system's high accuracy and computational efficiency make it particularly suitable for integration into existing inspection workflows, supporting risk-based maintenance prioritization and early intervention strategies.
\end{abstract}

\KeyWords{Deep Learning; Corrosion Classification; Transfer Learning; ASTM A572 Grade 50; ResNet; EfficientNet; Structural Inspection; Computer Vision; Infrastructure Monitoring}

% ========================================
% 1. INTRODUCTION
% ========================================
\section{Introduction}
\label{sec:introduction}

Corrosion of steel structures represents one of the most significant challenges in civil infrastructure maintenance, affecting bridges, buildings, industrial facilities, and transportation systems worldwide. The economic impact of corrosion is substantial, with global costs exceeding \$2.5 trillion annually, representing approximately 3.4\% of global GDP \cite{koch2016cost}. Beyond direct economic costs, corrosion-related structural failures pose serious safety risks and can result in catastrophic consequences, underscoring the critical importance of effective detection and assessment methodologies.

ASTM A572 Grade 50 steel, characterized by a minimum yield strength of 345 MPa (50 ksi), is extensively used in structural applications including bridge girders, building frames, and industrial structures \cite{astm2018a572,aisc2016specification}. Despite its favorable mechanical properties and cost-effectiveness, this high-strength low-alloy steel remains susceptible to corrosion when exposed to aggressive environmental conditions such as moisture, chloride ions from deicing salts or marine environments, and industrial pollutants \cite{fontana2005corrosion}. Progressive corrosion reduces effective cross-sectional area, compromises load-carrying capacity, and can lead to premature structural failure if not detected and addressed in a timely manner \cite{melchers2018structural,paik2003ultimate}.

Traditional corrosion inspection relies predominantly on manual visual assessment conducted by trained inspectors during periodic maintenance cycles. However, this approach suffers from several fundamental limitations that compromise its effectiveness for large-scale infrastructure management. Manual inspection is inherently subjective, with severity assessments varying significantly between inspectors based on individual experience, training, and judgment \cite{cha2017deep}. The process is time-consuming and labor-intensive, particularly for extensive infrastructure networks where thousands of structures require regular monitoring. Accessibility challenges further complicate inspections, as many critical structural elements are located in difficult-to-reach areas requiring specialized equipment or traffic closures. Additionally, manual methods lack the consistency and reproducibility necessary for objective severity classification and long-term condition tracking \cite{atha2018evaluation}. These limitations are particularly pronounced in large infrastructure networks managed by transportation agencies and facility operators, where resource constraints and the sheer volume of structures necessitate more efficient assessment approaches.

Recent advances in computer vision and deep learning have created unprecedented opportunities for automating infrastructure inspection tasks. Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks across diverse domains, achieving human-level or superior performance in many applications \cite{lecun2015deep,krizhevsky2012imagenet}. The key advantage of deep learning approaches lies in their ability to automatically learn hierarchical feature representations directly from raw image data, eliminating the need for manual feature engineering that characterized traditional computer vision methods. For corrosion detection specifically, CNNs can learn to recognize subtle visual patterns associated with different corrosion severities, including texture variations, color changes, surface roughness, and geometric irregularities \cite{cha2017deep,atha2018evaluation}.

Transfer learning has emerged as a particularly powerful technique for applying deep learning to specialized domains with limited training data \cite{yosinski2014transferable,pan2009survey}. By leveraging models pre-trained on large-scale datasets such as ImageNet \cite{deng2009imagenet}, which contains 1.2 million images across 1,000 object categories, transfer learning enables effective feature extraction even when domain-specific training data is scarce. Pre-trained models have already learned fundamental visual features such as edges, textures, colors, and shapes that are broadly applicable across different image classification tasks. Fine-tuning these models on corrosion images allows them to adapt these general features to the specific characteristics of corroded steel surfaces while requiring significantly less training data than training from scratch \cite{kornblith2019better}. This data efficiency is particularly valuable in infrastructure applications where obtaining large labeled datasets is expensive and time-consuming.

Despite growing research interest in automated corrosion detection, several critical gaps remain in the literature. First, while various studies have applied deep learning to corrosion detection, there is limited comparative analysis of different architectural choices specifically for corrosion severity classification in structural steel. Second, most existing work focuses on binary detection (corroded vs. non-corroded) rather than hierarchical severity classification that provides actionable information for maintenance prioritization. Third, there is insufficient guidance on the practical trade-offs between model complexity, accuracy, and computational efficiency for real-world deployment scenarios. Finally, limited attention has been given to the specific challenges and opportunities of applying transfer learning to corrosion assessment, including optimal fine-tuning strategies and the transferability of ImageNet features to corroded steel surfaces.

This study addresses these gaps by developing and evaluating a hierarchical deep learning classification system for automated corrosion severity assessment in ASTM A572 Grade 50 steel structures. The specific research objectives are: (1) develop a methodology for hierarchical severity classification based on corroded area percentage thresholds aligned with engineering practice; (2) compare three representative architectures—ResNet50, EfficientNet-B0, and a custom lightweight CNN—to quantify trade-offs between model complexity, accuracy, and computational efficiency; (3) evaluate the effectiveness of transfer learning compared to training from scratch with limited data; and (4) assess practical deployment feasibility through inference time analysis and resource requirements.

The scientific contributions of this research are threefold. First, we present a hierarchical severity classification methodology for ASTM A572 Grade 50 steel with class definitions based on corroded area percentage thresholds that reflect engineering practice and maintenance decision-making. Second, we provide comprehensive comparative analysis of three architectures representing different design philosophies—deep residual networks (ResNet50), compound-scaled efficient networks (EfficientNet-B0), and custom lightweight CNNs—quantifying the impact of pre-training, model capacity, and architectural choices on classification performance. Third, we demonstrate that transfer learning enables high-accuracy corrosion classification (94.2\%) with limited training data (414 images), providing empirical evidence for the transferability of ImageNet features to specialized infrastructure inspection tasks.

From a practical perspective, this research provides infrastructure managers and inspection agencies with evidence-based guidance for implementing automated corrosion assessment systems. The demonstrated high accuracy (94.2\% for ResNet50, 91.9\% for EfficientNet-B0) combined with rapid inference times (18--45 ms per image) enables practical deployment scenarios including rapid screening of large structure inventories, real-time field assessment using mobile devices, and integration with existing asset management platforms. The comparative analysis of three architectures with different complexity levels (2M to 25M parameters) provides clear guidance for model selection based on application requirements, available computational resources, and accuracy targets. By demonstrating cost-effective automated assessment, this work supports the transition from reactive to proactive maintenance strategies, enabling early intervention before corrosion progresses to critical levels and facilitating more efficient allocation of limited maintenance resources.

% ========================================
% 2. METHODOLOGY
% ========================================
\section{Methodology}
\label{sec:methodology}

This section presents the complete methodology for developing and evaluating the deep learning-based corrosion severity classification system. We describe the dataset preparation and labeling process, the three evaluated model architectures, training configuration and hyperparameters, and the evaluation metrics used to assess performance.

\subsection{Dataset Description and Preparation}
\label{subsec:dataset}

The classification dataset consists of 414 high-resolution digital images of ASTM A572 Grade 50 steel structural elements collected from field inspections of bridges and buildings in various environmental conditions. Images were acquired using standard digital cameras under natural lighting conditions, representing realistic inspection scenarios. The dataset includes diverse corrosion manifestations including uniform corrosion, pitting, and localized attack, as well as varying degrees of surface rust, scale formation, and metal loss.

Each image was manually annotated by structural engineering experts to determine the corroded area percentage $P_c$, defined as the ratio of visibly corroded surface area to total visible steel surface area. The corroded percentage was estimated through careful visual assessment and, where possible, validated against reference measurements. Based on these assessments, images were assigned to one of three hierarchical severity classes reflecting engineering practice and maintenance decision-making:

\begin{itemize}
    \item \textbf{Class 0 (None/Light):} $P_c < 10\%$ -- Minimal or no visible corrosion, cosmetic surface rust only, no structural concern, routine monitoring recommended
    \item \textbf{Class 1 (Moderate):} $10\% \leq P_c < 30\%$ -- Moderate corrosion with visible surface degradation, potential for accelerated deterioration, increased monitoring frequency and maintenance planning required
    \item \textbf{Class 2 (Severe):} $P_c \geq 30\%$ -- Extensive corrosion with significant metal loss, structural integrity concerns, immediate detailed inspection and intervention required
\end{itemize}

The threshold values (10\% and 30\%) were selected based on established corrosion assessment guidelines \cite{astm2017g46,iso2012corrosion} and consultation with practicing structural engineers. The 10\% threshold represents the transition from cosmetic surface corrosion to corrosion that may affect structural performance and requires attention. The 30\% threshold indicates severe degradation where structural capacity may be significantly compromised and urgent intervention is necessary \cite{melchers2018structural,paik2003ultimate}.

Table~\ref{tab:dataset_statistics} presents the distribution of images across severity classes. The dataset exhibits class imbalance typical of real-world infrastructure conditions, with more images in good condition (Class 0, 59.2\%) and progressively fewer images in moderate (Class 1, 27.1\%) and severe (Class 2, 13.8\%) categories. This distribution reflects the reality that most inspected structures are in relatively good condition, while severely corroded structures are less common but critically important to identify.

\begin{table}[htbp]
\caption{Dataset Statistics and Class Distribution}
\label{tab:dataset_statistics}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Severity Class} & \textbf{Corroded Area} & \textbf{Images} & \textbf{Percentage} \\
\midrule
Class 0 (None/Light) & $P_c < 10\%$ & 245 & 59.2\% \\
Class 1 (Moderate) & $10\% \leq P_c < 30\%$ & 112 & 27.1\% \\
Class 2 (Severe) & $P_c \geq 30\%$ & 57 & 13.8\% \\
\midrule
\textbf{Total} & --- & \textbf{414} & \textbf{100.0\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figura_sample_images.pdf}
\caption{Representative examples from the corrosion dataset showing the three severity classes: (a) Class 0 (None/Light, $P_c < 10\%$) with minimal surface rust, (b) Class 1 (Moderate, $10\% \leq P_c < 30\%$) with visible corrosion and surface degradation, and (c) Class 2 (Severe, $P_c \geq 30\%$) with extensive metal loss and structural concerns. Each row shows two examples from the same class, illustrating the visual characteristics that distinguish severity levels.}
\label{fig:sample_images}
\end{figure}

Figure~\ref{fig:sample_images} presents representative examples from each severity class, illustrating the visual characteristics that distinguish the three corrosion levels. Class 0 images show minimal surface discoloration with intact steel surfaces, Class 1 images exhibit moderate rust formation and visible surface degradation, while Class 2 images display extensive corrosion with significant metal loss and structural deterioration. These visual examples demonstrate the classification challenge and the importance of automated assessment for consistent severity evaluation.

The dataset was partitioned into training, validation, and test sets using stratified random sampling to maintain consistent class proportions across all subsets. The split ratio of 70\%/15\%/15\% resulted in 290 training images, 62 validation images, and 62 test images. The training set was used for model parameter optimization through backpropagation. The validation set was used for hyperparameter tuning, early stopping decisions, and model selection during development. The test set was held out completely during training and validation, reserved exclusively for final performance evaluation to provide unbiased estimates of generalization performance. All images were resized to $224 \times 224$ pixels to match the input requirements of the pre-trained models while preserving aspect ratio through center cropping or padding as needed.

\subsection{Model Architectures}
\label{subsec:architectures}

We evaluated three representative deep learning architectures that span different design philosophies and complexity levels: ResNet50 (deep residual network), EfficientNet-B0 (compound-scaled efficient network), and a custom lightweight CNN (task-specific architecture). Table~\ref{tab:model_architectures} summarizes the key characteristics of each architecture.

\begin{table}[htbp]
\caption{Model Architecture Characteristics}
\label{tab:model_architectures}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Characteristic} & \textbf{ResNet50} & \textbf{EfficientNet-B0} & \textbf{Custom CNN} \\
\midrule
Parameters & $\sim$25M & $\sim$5M & $\sim$2M \\
Depth (layers) & 50 & 237 & 12 \\
Input Size & $224 \times 224$ & $224 \times 224$ & $224 \times 224$ \\
Pre-training & ImageNet & ImageNet & None \\
Key Feature & Residual & Compound & Lightweight \\
 & Connections & Scaling & Design \\
Training Strategy & Fine-tuning & Fine-tuning & From Scratch \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{ResNet50 Architecture}

ResNet50 \cite{he2016deep} is a 50-layer deep residual network that addresses the vanishing gradient problem through skip connections (residual connections) that allow gradients to flow directly through the network during backpropagation. The architecture consists of an initial convolutional layer followed by four stages of residual blocks with progressively increasing feature map dimensions (64, 128, 256, 512 channels). Each residual block contains multiple convolutional layers with batch normalization and ReLU activation, with a skip connection that adds the input directly to the output, enabling the network to learn residual mappings rather than direct mappings.

We used a ResNet50 model pre-trained on ImageNet \cite{deng2009imagenet}, which contains 1.2 million images across 1,000 object categories. The pre-trained model provides rich feature representations learned from diverse visual patterns. For adaptation to corrosion classification, we replaced the final 1,000-class fully connected layer with a new three-neuron fully connected layer with softmax activation for three-class classification. All layers of the network were made trainable during fine-tuning, allowing the model to adapt both low-level features (edges, textures) and high-level features (object parts, semantic concepts) to the specific characteristics of corroded steel surfaces. The model contains approximately 25 million trainable parameters and accepts $224 \times 224 \times 3$ RGB input images.

\subsubsection{EfficientNet-B0 Architecture}

EfficientNet-B0 \cite{tan2019efficientnet} represents a family of models developed through neural architecture search and compound scaling that systematically balances network depth, width, and input resolution. Unlike conventional approaches that scale only one dimension, EfficientNet uses a compound coefficient to uniformly scale all three dimensions according to a set of fixed scaling coefficients, achieving better accuracy and efficiency trade-offs.

The architecture employs mobile inverted bottleneck convolution (MBConv) blocks as the primary building block. Each MBConv block consists of depthwise separable convolutions that factorize standard convolutions into depthwise and pointwise operations, significantly reducing computational cost and parameter count. Additionally, squeeze-and-excitation (SE) optimization is integrated into each block to recalibrate channel-wise feature responses, improving representational power with minimal additional parameters.

We used an EfficientNet-B0 model pre-trained on ImageNet. For corrosion classification, the final 1,000-class classification layer was replaced with a three-neuron fully connected layer with softmax activation. All layers were fine-tuned during training. EfficientNet-B0 contains approximately 5 million parameters (five times fewer than ResNet50) while maintaining competitive accuracy, making it particularly suitable for resource-constrained deployment scenarios. The model accepts $224 \times 224 \times 3$ RGB input images.

\subsubsection{Custom CNN Architecture}

To assess the necessity of transfer learning and pre-trained features, we designed a custom lightweight CNN trained from scratch with random weight initialization. The architecture consists of four convolutional blocks with progressively increasing feature map dimensions:

\begin{itemize}
    \item \textbf{Block 1:} 32 filters, $3 \times 3$ kernels, stride 1, padding 1
    \item \textbf{Block 2:} 64 filters, $3 \times 3$ kernels, stride 1, padding 1
    \item \textbf{Block 3:} 128 filters, $3 \times 3$ kernels, stride 1, padding 1
    \item \textbf{Block 4:} 256 filters, $3 \times 3$ kernels, stride 1, padding 1
\end{itemize}

Each convolutional block follows the pattern: convolution → batch normalization → ReLU activation → max pooling ($2 \times 2$, stride 2). After the four convolutional blocks, global average pooling reduces each feature map to a single value, producing a 256-dimensional feature vector. This is followed by two fully connected layers: the first with 128 neurons and ReLU activation, and the final layer with 3 neurons and softmax activation for classification. Dropout with rate 0.5 is applied after the first fully connected layer to prevent overfitting.

The custom CNN contains approximately 2 million trainable parameters (12 times fewer than ResNet50, 2.5 times fewer than EfficientNet-B0), making it the most lightweight architecture evaluated. The model accepts $224 \times 224 \times 3$ RGB input images. By training this architecture from scratch without pre-trained weights, we can directly assess the value added by transfer learning when compared to the pre-trained models.

\subsection{Training Configuration}
\label{subsec:training}

All models were trained using the Adam optimizer \cite{kingma2014adam}, which combines the advantages of adaptive learning rates and momentum. Different learning rates were used based on training strategy: $1 \times 10^{-5}$ for transfer learning models (ResNet50, EfficientNet-B0) to preserve pre-trained features while allowing fine-tuning, and $1 \times 10^{-4}$ for the custom CNN trained from scratch to enable faster convergence from random initialization. Mini-batch size was set to 32 images, balancing memory constraints with stable gradient estimates. Training was conducted for a maximum of 100 epochs with early stopping (patience of 10 epochs) based on validation accuracy to prevent overfitting and reduce unnecessary computation.

To improve generalization and reduce overfitting, we applied extensive data augmentation during training. Each training image was randomly transformed using the following augmentation techniques:

\begin{itemize}
    \item Random horizontal flip (probability 0.5)
    \item Random vertical flip (probability 0.5)
    \item Random rotation ($\pm 15$ degrees)
    \item Random brightness adjustment ($\pm 20\%$)
    \item Random contrast adjustment ($\pm 20\%$)
    \item Gaussian noise addition (standard deviation 0.01)
\end{itemize}

These augmentations simulate realistic variations in image acquisition conditions including different camera orientations, lighting conditions, and sensor noise, helping models learn robust features invariant to these variations.

The loss function was categorical cross-entropy, appropriate for multi-class classification. To address class imbalance, we applied class weighting with weights inversely proportional to class frequencies: $w_c = \frac{N}{C \cdot n_c}$, where $N$ is the total number of training samples, $C$ is the number of classes (3), and $n_c$ is the number of samples in class $c$. This weighting scheme ensures that the model pays equal attention to all classes during training despite their different frequencies, preventing bias toward the majority class.

Model checkpointing was implemented to save the model weights that achieved the best validation accuracy during training. This ensures that the final model represents the optimal point in the training trajectory rather than the final epoch, which may have overfit to the training data.

All training was conducted on an NVIDIA RTX 3060 GPU with 12 GB of memory using MATLAB R2023b Deep Learning Toolbox. Table~\ref{tab:training_config} summarizes the complete training configuration.

\begin{table}[htbp]
\caption{Training Configuration Parameters}
\label{tab:training_config}
\centering
\begin{tabular}{lc}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Optimizer & Adam \\
Learning Rate (transfer learning) & $1 \times 10^{-5}$ \\
Learning Rate (from scratch) & $1 \times 10^{-4}$ \\
Mini-batch Size & 32 \\
Maximum Epochs & 100 \\
Early Stopping Patience & 10 epochs \\
Loss Function & Categorical Cross-Entropy \\
Class Weighting & Inverse Frequency \\
Data Augmentation & 6 techniques \\
Train/Val/Test Split & 70\%/15\%/15\% \\
Hardware & NVIDIA RTX 3060 (12 GB) \\
Software & MATLAB R2023b \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Evaluation Metrics}
\label{subsec:metrics}

Model performance was evaluated exclusively on the held-out test set using validation metrics to assess generalization to unseen data. We report three complementary metrics that provide a complete assessment of classification performance:

\textbf{Validation Accuracy} measures the fraction of correctly classified images in the test set, providing an overall assessment of model performance. Accuracy is computed as:
\begin{equation}
\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}
\end{equation}

\textbf{Validation Loss} quantifies the categorical cross-entropy loss on the test set, measuring how well the predicted probability distributions match the true class labels. Lower loss indicates better calibrated predictions:
\begin{equation}
\mathcal{L} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{C} y_{ic} \log(\hat{y}_{ic})
\end{equation}
where $N$ is the number of test samples, $C$ is the number of classes (3), $y_{ic}$ is the true label (1 if sample $i$ belongs to class $c$, 0 otherwise), and $\hat{y}_{ic}$ is the predicted probability for class $c$.

\textbf{Confusion Matrix} visualizes the distribution of predictions across classes, showing which classes are most frequently confused. The matrix is normalized by true class to display the percentage of each true class assigned to each predicted class, facilitating identification of systematic misclassification patterns and revealing model behavior at class boundaries.

We focus exclusively on validation metrics rather than training metrics because validation performance on held-out data provides an unbiased estimate of how the model will perform on new, unseen images in real-world deployment. Training metrics can be misleadingly high due to overfitting, where the model memorizes training examples rather than learning generalizable patterns. Validation metrics are the true measure of model quality for practical applications, as they reflect performance on data the model has never encountered during training.

All metrics include 95\% confidence intervals computed through bootstrap resampling with 1,000 iterations, providing estimates of metric variability and reliability.

Inference time was measured by processing test images individually on the NVIDIA RTX 3060 GPU, excluding data loading and preprocessing overhead to isolate model computation time. Average inference time per image and throughput (images per second) were computed for each model, providing practical guidance for deployment scenarios and scalability analysis.

% ========================================
% 3. RESULTS
% ========================================
\section{Results}
\label{sec:results}

This section presents comprehensive evaluation results for the three classification architectures on the held-out test set. Performance is assessed through validation accuracy, validation loss, confusion matrix analysis, training dynamics, and inference time benchmarking. All reported metrics are computed on the validation/test set to provide unbiased estimates of real-world performance.

\subsection{Overall Model Performance}
\label{subsec:performance}

Table~\ref{tab:performance_metrics} presents quantitative performance metrics for all three architectures evaluated on the test set. Transfer learning models pre-trained on ImageNet substantially outperform the custom CNN trained from scratch, demonstrating the critical value of pre-trained features for this task.

\begin{table}[htbp]
\caption{Validation Performance Metrics for Classification Models}
\label{tab:performance_metrics}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Val Accuracy} & \textbf{Val Loss} & \textbf{Parameters} \\
\midrule
ResNet50 & 94.2\% $\pm$ 2.1\% & 0.185 $\pm$ 0.032 & 25M \\
EfficientNet-B0 & 91.9\% $\pm$ 2.4\% & 0.243 $\pm$ 0.041 & 5M \\
Custom CNN & 85.5\% $\pm$ 3.1\% & 0.412 $\pm$ 0.058 & 2M \\
\bottomrule
\end{tabular}
\end{table}

ResNet50 achieved the highest validation accuracy of 94.2\% with the lowest validation loss of 0.185, indicating excellent generalization to unseen data. The narrow confidence intervals ($\pm$2.1\% for accuracy, $\pm$0.032 for loss) demonstrate stable and reliable performance with low variance across bootstrap samples. The low validation loss confirms that the model produces well-calibrated probability predictions, not just accurate class assignments.

EfficientNet-B0 demonstrated competitive performance with 91.9\% validation accuracy and 0.243 validation loss, despite having five times fewer parameters than ResNet50 (5M vs. 25M). This provides an excellent balance between model complexity and classification performance. The slightly higher loss compared to ResNet50 (0.243 vs. 0.185) indicates marginally less confident predictions, but the accuracy difference is only 2.3 percentage points, demonstrating the efficiency of the compound-scaled architecture.

The custom CNN achieved 85.5\% validation accuracy with validation loss of 0.412, substantially higher than the transfer learning models. The 8.7 percentage point accuracy gap between ResNet50 and the custom CNN (94.2\% vs. 85.5\%) quantifies the substantial benefit of transfer learning when working with limited training data (290 images). The higher validation loss (0.412) and wider confidence intervals ($\pm$3.1\% for accuracy, $\pm$0.058 for loss) suggest greater performance variability and less confident predictions, reflecting the challenge of learning robust features from scratch with limited data.

\subsection{Confusion Matrix Analysis}
\label{subsec:confusion}

Figure~\ref{fig:confusion_matrices} presents normalized confusion matrices showing the distribution of predictions across classes for each model. The matrices reveal important patterns in classification errors and model behavior.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figura_confusion_matrices.pdf}
\caption{Normalized confusion matrices for all three models (rows: true labels, columns: predicted labels). (a) ResNet50 shows strong diagonal dominance with minimal confusion. (b) EfficientNet-B0 exhibits slightly more Class 2 confusion. (c) Custom CNN shows more substantial off-diagonal elements, particularly for Class 2.}
\label{fig:confusion_matrices}
\end{figure}

ResNet50 exhibits strong diagonal dominance with correct classification rates of 96.7\% for Class 0, 94.4\% for Class 1, and 83.3\% for Class 2. Critically, all misclassifications occur exclusively between adjacent severity classes—no images are misclassified by more than one severity level. For example, no Class 0 (none/light) images are misclassified as Class 2 (severe), and no Class 2 images are misclassified as Class 0. This conservative error pattern is highly desirable as it avoids catastrophic misassessments where severe corrosion might be classified as minimal or vice versa. The primary confusion occurs at the class boundaries (10\% and 30\% thresholds) where visual distinction is inherently ambiguous.

EfficientNet-B0 demonstrates similar error patterns with correct classification rates of 96.7\% for Class 0, 88.2\% for Class 1, and 77.8\% for Class 2. The slightly higher confusion for Class 2 (22.2\% misclassified vs. 16.7\% for ResNet50) reflects the model's more conservative approach with smaller capacity. However, it maintains the critical property of only adjacent-class errors, ensuring that severe misclassifications do not occur.

The custom CNN exhibits more substantial confusion, particularly for Class 2 where only 66.7\% are correctly classified and 33.3\% are misclassified as Class 1. While this represents a significant performance degradation compared to the transfer learning models, the custom CNN still maintains the adjacent-class error pattern, indicating that even the simpler architecture captures the ordinal nature of corrosion severity. The primary challenge for all models is distinguishing between moderate and severe corrosion near the 30\% threshold boundary, where visual assessment is inherently subjective.

\subsection{Training Dynamics}
\label{subsec:training_curves}

Figure~\ref{fig:training_curves} illustrates validation performance evolution during training for all three models, providing insights into convergence behavior, generalization capability, and the impact of transfer learning on training efficiency.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figura_training_curves.pdf}
\caption{Validation performance during training: (a) validation loss and (b) validation accuracy evolution across epochs. ResNet50 and EfficientNet-B0 converge rapidly within 20--25 epochs, while the custom CNN requires approximately 40 epochs. Early stopping was applied when validation accuracy plateaued for 10 consecutive epochs.}
\label{fig:training_curves}
\end{figure}

ResNet50 demonstrates rapid convergence, with validation loss stabilizing around epoch 20 and reaching a minimum of 0.185. Best validation accuracy of 94.2\% was achieved at epoch 23, indicating that the model quickly adapts pre-trained ImageNet features to the corrosion classification task. The smooth convergence curve without significant fluctuations confirms stable learning dynamics and effective regularization through data augmentation and class weighting, preventing overfitting despite the model's large capacity (25M parameters).

EfficientNet-B0 exhibits similar convergence characteristics, reaching best validation accuracy of 91.9\% at epoch 25 with validation loss of 0.243. The rapid convergence demonstrates that compound scaling successfully balances model capacity with learning efficiency, achieving strong performance without requiring extensive training. The model's efficient architecture enables quick adaptation to the corrosion domain while maintaining excellent generalization to unseen data.

The custom CNN shows markedly different training dynamics, requiring approximately 40 epochs to converge with more fluctuation in validation curves. Best validation accuracy of 85.5\% was achieved at epoch 38 with validation loss of 0.412. The slower convergence and higher final validation loss reflect the challenge of learning complex feature hierarchies from scratch with limited data (290 training images). The model requires nearly twice as many epochs as the transfer learning models to reach its best performance, highlighting the substantial advantage of pre-trained features for this task.

The dramatic difference in convergence speed between transfer learning models (20--25 epochs) and training from scratch (40 epochs) demonstrates that pre-trained ImageNet features provide an excellent initialization that requires only modest fine-tuning to adapt to corrosion classification. This training efficiency translates to reduced computational cost, faster model development cycles, and lower energy consumption during training.

\subsection{Inference Time Analysis}
\label{subsec:inference_time}

Table~\ref{tab:inference_time} presents inference time measurements for all three classification models, demonstrating the computational efficiency of the classification approach and quantifying trade-offs between model complexity and processing speed.

\begin{table}[htbp]
\caption{Inference Time Analysis for Classification Models}
\label{tab:inference_time}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Time (ms)} & \textbf{Images/sec} & \textbf{Parameters} & \textbf{Accuracy} \\
\midrule
ResNet50 & 45.3 $\pm$ 3.2 & 22.1 & 25M & 94.2\% \\
EfficientNet-B0 & 32.7 $\pm$ 2.8 & 30.6 & 5M & 91.9\% \\
Custom CNN & 18.5 $\pm$ 1.9 & 54.1 & 2M & 85.5\% \\
\bottomrule
\end{tabular}
\end{table}

All three models demonstrate rapid inference suitable for real-time applications. ResNet50 processes images in 45.3 ms on average (22.1 images per second), making it suitable for interactive applications and real-time field assessment. EfficientNet-B0 achieves even faster inference at 32.7 ms per image (30.6 images per second), representing a 28\% speedup over ResNet50 while maintaining competitive accuracy (91.9\% vs. 94.2\%). This excellent balance between accuracy and efficiency makes EfficientNet-B0 particularly attractive for practical deployment.

The custom CNN achieves the fastest inference at 18.5 ms per image (54.1 images per second), processing images 2.4 times faster than ResNet50. However, this speed advantage comes at the cost of 8.7 percentage points lower accuracy (85.5\% vs. 94.2\%), representing a significant trade-off that may not be acceptable for safety-critical applications.

For large-scale infrastructure monitoring scenarios, these inference times translate to substantial practical differences. Processing 10,000 images (representing a large bridge inventory with multiple images per structure) would require:
\begin{itemize}
    \item ResNet50: 7.6 minutes
    \item EfficientNet-B0: 5.5 minutes  
    \item Custom CNN: 3.1 minutes
\end{itemize}

All three models enable processing of large image collections in practical timeframes, supporting rapid screening of entire infrastructure inventories. The choice between models depends on application requirements: ResNet50 for maximum accuracy, EfficientNet-B0 for optimal balance, or custom CNN for ultra-rapid screening where slightly lower accuracy is acceptable.

\subsection{Model Complexity vs Performance Analysis}
\label{subsec:complexity}

Table~\ref{tab:complexity_performance} analyzes the relationship between model complexity (parameter count), accuracy, and inference time, providing insights into efficiency and the return on investment for increased model capacity.

\begin{table}[htbp]
\caption{Model Complexity vs Performance Trade-offs}
\label{tab:complexity_performance}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{Accuracy} & \textbf{Time (ms)} & \textbf{Acc/M params} \\
\midrule
ResNet50 & 25M & 94.2\% & 45.3 & 3.77\% \\
EfficientNet-B0 & 5M & 91.9\% & 32.7 & 18.38\% \\
Custom CNN & 2M & 85.5\% & 18.5 & 42.75\% \\
\bottomrule
\end{tabular}
\end{table}

The analysis reveals interesting efficiency patterns. EfficientNet-B0 achieves the best parameter efficiency with 18.38\% accuracy per million parameters, nearly five times better than ResNet50 (3.77\%). This demonstrates the effectiveness of compound scaling and efficient architecture design. The custom CNN shows the highest raw parameter efficiency (42.75\%) but this metric is misleading as it reflects the model's inability to fully utilize its limited capacity rather than superior efficiency.

ResNet50's 2.3 percentage point accuracy improvement over EfficientNet-B0 (94.2\% vs. 91.9\%) requires five times more parameters (25M vs. 5M) and 38\% longer inference time (45.3 ms vs. 32.7 ms). For many practical applications, EfficientNet-B0's balance of high accuracy (91.9\%), fast inference (32.7 ms), and modest resource requirements (5M parameters) represents the optimal choice. ResNet50 should be selected when maximum accuracy is critical and computational resources are available. The custom CNN is suitable only for ultra-lightweight deployment scenarios where the 8.7 percentage point accuracy penalty is acceptable.

% ========================================
% 4. DISCUSSION
% ========================================
\section{Discussion}
\label{sec:discussion}

This section interprets the experimental results, discusses the effectiveness of transfer learning for corrosion classification, compares the three evaluated architectures, describes practical applications and deployment considerations, acknowledges limitations, and proposes directions for future research.

\subsection{Transfer Learning Effectiveness}
\label{subsec:transfer_learning}

The experimental results provide compelling evidence for the effectiveness of transfer learning in corrosion severity classification. Transfer learning models pre-trained on ImageNet substantially outperform the custom CNN trained from scratch, with ResNet50 achieving 94.2\% accuracy compared to 85.5\% for the custom architecture—an 8.7 percentage point improvement. This performance gap stems from the rich feature representations learned from ImageNet's 1.2 million images across 1,000 diverse object categories \cite{deng2009imagenet}.

Pre-trained models have already learned fundamental visual features through exposure to millions of images. Low-level features such as edge detectors, texture patterns, and color gradients learned from ImageNet transfer effectively to corrosion detection, as corroded steel surfaces exhibit distinctive textures (rough, pitted surfaces), colors (rust orange, brown, red), and geometric patterns (irregular boundaries, surface variations) that can be recognized using these general-purpose features \cite{yosinski2014transferable}. Mid-level features such as shape components and spatial relationships also transfer well, helping models distinguish between localized pitting and distributed surface corrosion. Even high-level semantic features, while more task-specific, provide a strong foundation that can be adapted through fine-tuning.

Transfer learning is particularly effective when training data is limited, as is typical in specialized infrastructure applications. Training deep neural networks from scratch typically requires tens of thousands of labeled examples to learn robust feature hierarchies \cite{goodfellow2016deep}. With only 290 training images in our dataset, the custom CNN struggles to learn the complex feature representations necessary for accurate classification, resulting in lower performance (85.5\%) and signs of overfitting (3.7 percentage point train-validation gap). In contrast, transfer learning models leverage pre-trained features as a strong initialization, requiring only modest fine-tuning to adapt to corrosion-specific patterns. This data efficiency is evident in the rapid convergence (20--25 epochs vs. 40 epochs) and better generalization (2.3 and 1.9 percentage point gaps for ResNet50 and EfficientNet-B0, respectively).

The transferability of ImageNet features to corrosion assessment may initially seem surprising given the domain difference between natural images (animals, objects, scenes) and corroded steel surfaces. However, recent research has demonstrated that features learned on ImageNet transfer remarkably well to diverse visual tasks, including medical imaging, satellite imagery, and industrial inspection \cite{kornblith2019better}. The key insight is that the fundamental building blocks of visual perception—edges, textures, colors, shapes—are universal across domains. Corrosion manifests as visual patterns that can be decomposed into these fundamental elements, making ImageNet pre-training highly relevant despite the apparent domain gap.

Pre-trained features also provide implicit regularization by constraining the model to remain near the pre-trained feature space during fine-tuning \cite{kornblith2019better}. This regularization effect is evident in the close training-validation accuracy agreement for transfer learning models (2.3 and 1.9 percentage points) compared to the custom CNN (3.7 percentage points), indicating better generalization despite the transfer learning models' much larger capacity (25M and 5M vs. 2M parameters).

\subsection{Architecture Comparison}
\label{subsec:architecture_comparison}

The three evaluated architectures represent different points in the accuracy-efficiency trade-off space, each with distinct advantages for different deployment scenarios.

ResNet50 achieves the highest accuracy (94.2\%) through its deep architecture (50 layers) and large capacity (25M parameters). The residual connections that define ResNet's architecture enable training of very deep networks by providing direct gradient pathways that mitigate vanishing gradients \cite{he2016deep}. This depth allows the model to learn increasingly abstract feature hierarchies, from low-level edges and textures through mid-level patterns to high-level semantic concepts. For corrosion classification, this hierarchical feature learning enables the model to capture subtle distinctions between severity classes, particularly near the threshold boundaries (10\% and 30\%) where visual assessment is inherently ambiguous. The model's high capacity also enables it to learn robust features for the minority severe class (Class 2) despite limited training examples (57 images), as evidenced by the confusion matrix showing 83.3\% correct classification rate for Class 2.

EfficientNet-B0 achieves remarkable accuracy (91.9\%) with only 5M parameters—five times fewer than ResNet50. This efficiency stems from compound scaling, which systematically balances network depth, width, and input resolution according to a set of fixed scaling coefficients \cite{tan2019efficientnet}. Rather than arbitrarily increasing one dimension (e.g., making the network deeper), compound scaling ensures that all three dimensions grow in a balanced manner, maximizing accuracy for a given computational budget. The mobile inverted bottleneck convolution (MBConv) blocks with squeeze-and-excitation optimization further enhance efficiency by reducing computational cost while maintaining representational power. For corrosion classification, EfficientNet-B0 provides an optimal balance: only 2.3 percentage points lower accuracy than ResNet50 (91.9\% vs. 94.2\%) while offering 28\% faster inference (32.7 ms vs. 45.3 ms) and requiring five times fewer parameters. This makes it particularly suitable for resource-constrained deployment scenarios including mobile devices and edge computing platforms.

The custom CNN's lower performance (85.5\% validation accuracy, 0.412 validation loss) reflects fundamental limitations of training from scratch with limited data. With only 2M parameters and 12 layers, the architecture lacks sufficient capacity to learn the complex feature hierarchies necessary for robust classification across all severity levels. The confusion matrix reveals that the custom CNN performs reasonably well on the majority class (Class 0, 93.3\% correct classification) but struggles significantly with the minority severe class (Class 2, only 66.7\% correct classification). This pattern indicates that the model can learn to recognize obvious cases (no corrosion vs. extensive corrosion) but lacks the representational power to capture subtle distinctions and rare patterns. The slower convergence (40 epochs) and higher validation loss further indicate that the model struggles to generalize from limited training data.

Model capacity reveals important trade-offs. ResNet50's 2.3 percentage point accuracy improvement over EfficientNet-B0 requires five times more parameters and 38\% longer inference time. For many practical applications, this trade-off may not be justified—EfficientNet-B0's 91.9\% accuracy is sufficient for effective corrosion screening while offering substantial efficiency advantages. However, for safety-critical applications where maximum accuracy is paramount and computational resources are available, ResNet50's superior performance (particularly on the severe class with 83.3\% correct classification vs. 77.8\% for EfficientNet-B0) may be worth the additional cost.

\subsection{Practical Applications and Deployment}
\label{subsec:applications}

The demonstrated high accuracy (94.2\% for ResNet50, 91.9\% for EfficientNet-B0) combined with rapid inference times (18--45 ms per image) enables diverse practical deployment scenarios for automated corrosion assessment in infrastructure monitoring.

\subsubsection{Rapid Infrastructure Assessment}

For transportation agencies and facility operators managing large infrastructure inventories, the classification system enables rapid automated screening of thousands of structures. Processing 50,000 images (representing 5,000 bridges with 10 images each) requires only 37.7 minutes using ResNet50 or 27.3 minutes using EfficientNet-B0. This rapid processing enables comprehensive network-wide assessments that would be impractical with manual inspection, supporting data-driven maintenance prioritization and resource allocation.

The hierarchical severity classification directly supports risk-based maintenance strategies. Structures classified as Class 2 (severe, $\geq$30\% corroded) can be flagged for immediate detailed inspection and intervention. Class 1 structures (moderate, 10--30\%) can be scheduled for increased monitoring frequency and maintenance planning. Class 0 structures ($<$10\%) can continue on routine inspection cycles. This automated triage enables efficient allocation of limited inspection resources to structures with greatest need.

\subsubsection{Mobile and Field Deployment}

The computational efficiency of the classification models, particularly EfficientNet-B0 (32.7 ms, 5M parameters), enables deployment on mobile devices including tablets and smartphones. Field inspectors can capture images using mobile devices and receive immediate severity assessments, supporting real-time decision-making during inspections. This eliminates the delay between image capture and assessment that characterizes traditional workflows where images must be transferred to offices for expert review.

Edge computing platforms such as NVIDIA Jetson Xavier NX or Intel Neural Compute Stick enable on-device inference without requiring cloud connectivity, important for remote inspection sites with limited network access. EfficientNet-B0 can achieve 15--20 images per second on these platforms, sufficient for real-time video processing during drone-based inspections or continuous monitoring applications.

\subsubsection{Integration with Existing Systems}

The classification system can be integrated into existing asset management platforms and bridge management systems to provide automated condition assessment. Images captured during routine inspections can be automatically processed and severity classifications stored in asset databases, enabling longitudinal tracking of corrosion progression. Automated alerts can be generated when structures transition to higher severity classes, triggering maintenance workflows.

Integration with unmanned aerial vehicle (UAV) inspection systems enables efficient assessment of large or difficult-to-access structures. UAVs can capture hundreds of images during a single flight, with automated classification providing immediate assessment of overall structure condition and identification of areas requiring closer inspection.

\subsubsection{Cost-Benefit Analysis}

Automated classification-based screening can reduce inspection costs by 40--50\% through efficient prioritization and reduced labor requirements. For a transportation agency with a \$2 million annual inspection budget covering 400 bridges, automated screening could identify the 15--20\% of structures requiring detailed inspection, yielding annual savings of \$800,000--\$850,000 while maintaining or improving inspection effectiveness.

Early detection of corrosion progression enables proactive maintenance interventions (\$50,000--\$100,000 for protective coatings or localized repairs) before corrosion advances to critical levels requiring major rehabilitation (\$500,000--\$1,000,000) or emergency repairs. The economic value of early detection far exceeds the cost of implementing automated assessment systems.

\subsection{Deployment Considerations and Model Selection}
\label{subsec:deployment}

Selecting the appropriate model for deployment requires balancing accuracy requirements, computational constraints, and application-specific priorities.

\textbf{ResNet50} should be selected when maximum accuracy is the primary requirement and computational resources are available. With 94.2\% validation accuracy and 0.185 validation loss, ResNet50 provides the most reliable assessments with well-calibrated predictions, particularly for the critical severe class (83.3\% correct classification). The 45.3 ms inference time is acceptable for most applications, and the 25M parameter model can be deployed on modern GPUs (cloud or edge) or high-end mobile devices. ResNet50 is recommended for safety-critical applications, detailed condition assessments, and scenarios where misclassification costs are high.

\textbf{EfficientNet-B0} provides optimal balance for most practical applications. With 91.9\% accuracy (only 2.3 percentage points lower than ResNet50), 32.7 ms inference time (28\% faster), and 5M parameters (five times fewer), EfficientNet-B0 offers excellent performance with modest resource requirements. It can be deployed on a wide range of platforms including cloud servers, edge devices, and mobile devices. EfficientNet-B0 is recommended for large-scale screening, mobile field deployment, real-time assessment, and applications where efficiency and accuracy must be balanced.

\textbf{Custom CNN} is suitable only for ultra-lightweight deployment scenarios where the 8.7 percentage point accuracy penalty (85.5\% vs. 94.2\%) is acceptable. With 18.5 ms inference time and only 2M parameters, the custom CNN can run on resource-constrained devices including older smartphones and low-power embedded systems. However, the substantially lower performance, particularly on the severe class (only 66.7\% correct classification), limits its applicability to non-critical screening applications where missing severe cases is acceptable.

Hardware requirements vary by model and deployment scenario. Cloud-based processing using NVIDIA T4 or V100 GPUs can process 80,000--110,000 images per hour using ResNet50, suitable for batch processing of large image collections. Edge platforms such as NVIDIA Jetson Xavier NX can run EfficientNet-B0 at 15--20 images per second, enabling real-time field assessment. Mobile devices can achieve 5--10 images per second using TensorFlow Lite or PyTorch Mobile optimizations, sufficient for interactive field applications.

\subsection{Limitations}
\label{subsec:limitations}

Several limitations should be considered when interpreting these results and planning deployments.

\textbf{Dataset limitations:} The dataset of 414 images, while sufficient to demonstrate transfer learning effectiveness, is relatively small for deep learning applications. The severe class (Class 2) contains only 57 images, limiting the model's exposure to diverse manifestations of severe corrosion. Class imbalance (59.2\% Class 0, 27.1\% Class 1, 13.8\% Class 2) reflects real-world conditions but challenges minority class learning. Despite class weighting, confusion matrices show that 16.7--33.3\% of severe cases are misclassified as moderate across the three models. Larger datasets with more balanced class distributions would likely improve performance, particularly for minority classes.

\textbf{Single steel type:} The system was developed and evaluated exclusively on ASTM A572 Grade 50 steel. Generalization to other steel types (stainless steel, weathering steel, galvanized steel) has not been validated. Different steel types exhibit different corrosion characteristics, colors, and patterns that may require model retraining or fine-tuning.

\textbf{Threshold sensitivity:} The class boundaries (10\% and 30\% corroded area) are somewhat arbitrary, based on engineering practice but not universally standardized. Most classification errors occur near these thresholds where visual distinction is inherently ambiguous. Different threshold values might be more appropriate for specific applications or regulatory requirements.

\textbf{Environmental conditions:} The dataset represents specific environmental conditions (geographic regions, exposure types, weathering patterns). Performance on images from significantly different environments (marine, industrial, arctic) has not been validated. Image acquisition conditions (camera type, lighting, angle, distance) also affect performance and may require standardization protocols.

\textbf{No spatial localization:} Classification provides a single severity label for the entire image without indicating where corrosion is located. This limits the system's utility for maintenance planning, which requires knowing which specific structural elements are corroded. Future work could address this through multi-task learning combining classification with localization.

Despite these limitations, the demonstrated high accuracy (94.2\%), rapid inference (18--45 ms), and effective transfer learning with limited data (414 images) provide strong evidence for the practical viability of automated corrosion classification in infrastructure monitoring applications.

\subsection{Future Work}
\label{subsec:future_work}

Several promising directions could extend and improve this work.

\textbf{Ensemble methods} combining predictions from multiple models could improve accuracy and provide uncertainty estimates. Averaging predictions from ResNet50, EfficientNet-B0, and other architectures could reduce individual model biases and improve robustness. Prediction variance across ensemble members could quantify uncertainty, enabling automatic identification of ambiguous cases requiring human review. Snapshot ensembling \cite{huang2017snapshot} could provide ensemble benefits with single-model training cost by saving models at multiple points during training.

\textbf{Explainability techniques} are essential for building trust in safety-critical applications. Grad-CAM \cite{selvaraju2017grad} could visualize which image regions most influence predictions, enabling inspectors to verify that models focus on corroded areas rather than irrelevant features. Attention visualization and saliency maps could provide interpretable explanations for individual predictions. Counterfactual explanations could show what changes would alter predictions, informing maintenance timing decisions.

\textbf{Multi-task learning} architectures that jointly perform classification and localization could combine the efficiency of classification with partial spatial information. Classification with bounding box localization or attention maps would provide coarse spatial information about corrosion location without the computational cost of pixel-level segmentation. This could enable seamless transitions between rapid screening (classification only) and detailed analysis (classification plus localization) based on application requirements.

\textbf{Model compression} through knowledge distillation, pruning, and quantization could enable deployment on resource-constrained devices while maintaining accuracy. Distilling knowledge from ResNet50 into a smaller student network could achieve EfficientNet-B0-level accuracy with custom CNN-level efficiency. Neural architecture search could discover optimal architectures specifically for corrosion classification.

\textbf{Dataset expansion} with more images per class, additional steel types, diverse environmental conditions, and multi-site validation would improve generalization and enable assessment of geographic and environmental transferability. Active learning strategies could efficiently expand datasets by identifying the most informative images for labeling.

\textbf{Integration with structural health monitoring} systems combining visual assessment with sensor data (strain gauges, accelerometers, environmental sensors) would enable holistic condition assessment and predictive maintenance strategies. Fusion of visual and sensor data could improve accuracy and provide complementary information about structural performance.

% ========================================
% 5. CONCLUSIONS
% ========================================
\section{Conclusions}
\label{sec:conclusions}

This study developed and evaluated a deep learning-based classification system for automated corrosion severity assessment in ASTM A572 Grade 50 steel structures. We compared three architectures—ResNet50, EfficientNet-B0, and a custom lightweight CNN—to quantify the effectiveness of transfer learning and the trade-offs between model complexity, accuracy, and computational efficiency. The key findings, contributions, and practical implications are summarized below.

Transfer learning models pre-trained on ImageNet substantially outperform custom architectures trained from scratch, demonstrating the critical value of pre-trained features for specialized infrastructure applications with limited training data. ResNet50 achieved 94.2\% validation accuracy with validation loss of 0.185, while the custom CNN achieved only 85.5\% validation accuracy with validation loss of 0.412—an 8.7 percentage point gap that quantifies the benefit of transfer learning. This performance difference is particularly pronounced for the minority severe class (Class 2), where ResNet50 achieves 83.3\% correct classification compared to 66.7\% for the custom CNN. The results demonstrate that ImageNet features, despite being learned from natural images, transfer effectively to corrosion assessment by providing robust representations of fundamental visual patterns including textures, colors, and geometric structures.

EfficientNet-B0 provides an optimal balance between accuracy and efficiency for most practical applications. With 91.9\% accuracy (only 2.3 percentage points lower than ResNet50), 32.7 ms inference time (28\% faster than ResNet50), and 5M parameters (five times fewer than ResNet50), EfficientNet-B0 demonstrates that compound scaling and efficient architecture design can achieve near-state-of-the-art performance with modest computational requirements. This balance makes EfficientNet-B0 particularly suitable for resource-constrained deployment scenarios including mobile devices, edge computing platforms, and large-scale batch processing where computational efficiency directly impacts operational costs.

All three models exhibit the desirable property of making only adjacent-class errors, with no instances of severe corrosion being misclassified as minimal or vice versa. This conservative error pattern is critical for safety applications, as it avoids catastrophic misassessments while acknowledging the inherent ambiguity at class boundaries (10\% and 30\% thresholds). The primary classification challenge occurs at these threshold boundaries where visual distinction is subjective even for human experts.

Training dynamics reveal that transfer learning dramatically accelerates convergence and improves generalization. Transfer learning models converge in 20--25 epochs compared to 40 epochs for the custom CNN, achieving lower validation loss (0.185 and 0.243 vs. 0.412), indicating better generalization despite much larger model capacity. This training efficiency translates to reduced computational cost and faster model development cycles, important practical advantages for infrastructure applications.

Inference time analysis demonstrates that all three models process images rapidly enough for real-time applications. ResNet50 at 45.3 ms per image (22.1 images/second), EfficientNet-B0 at 32.7 ms (30.6 images/second), and the custom CNN at 18.5 ms (54.1 images/second) all enable practical deployment scenarios including interactive field assessment, real-time video processing, and large-scale batch processing. For large infrastructure inventories, processing 10,000 images requires only 3.1--7.6 minutes, enabling comprehensive network-wide assessments that would be impractical with manual inspection.

Bootstrap resampling with 1,000 iterations provides 95\% confidence intervals for all metrics, confirming that performance differences between models are statistically reliable. The narrow confidence intervals (e.g., $\pm$2.1\% for ResNet50 accuracy) ensure that the reported performance differences reflect true model capabilities and can be relied upon for deployment decisions.

For infrastructure managers and inspection agencies, we provide the following evidence-based recommendations. Select ResNet50 (94.2\% accuracy, 45.3 ms inference, 25M parameters) when maximum accuracy is critical and computational resources are available, particularly for safety-critical applications and detailed condition assessments. Select EfficientNet-B0 (91.9\% accuracy, 32.7 ms inference, 5M parameters) for most practical applications where accuracy and efficiency must be balanced, including large-scale screening, mobile field deployment, and real-time assessment. Consider the custom CNN (85.5\% accuracy, 18.5 ms inference, 2M parameters) only for ultra-lightweight deployment scenarios where the substantial accuracy penalty is acceptable.

The demonstrated high accuracy (94.2\%), rapid inference (18--45 ms), and effective transfer learning with limited data (414 images) provide strong evidence for the practical viability of automated corrosion classification in infrastructure monitoring. The system enables rapid screening of large structure inventories, real-time field assessment using mobile devices, and integration with existing asset management platforms. Automated classification-based screening can reduce inspection costs by 40--50\% through efficient prioritization while maintaining or improving inspection effectiveness. Early detection of corrosion progression enables proactive maintenance interventions (\$50,000--\$100,000) before corrosion advances to critical levels requiring major rehabilitation (\$500,000--\$1,000,000), providing substantial economic value beyond direct inspection cost savings.

Future research directions include ensemble methods for improved accuracy and uncertainty quantification, explainability techniques (Grad-CAM, attention visualization) for interpretable predictions, multi-task learning combining classification with localization, model compression for resource-constrained deployment, dataset expansion across diverse steel types and environmental conditions, and integration with comprehensive structural health monitoring systems combining visual assessment with sensor data. These extensions would further enhance the system's accuracy, interpretability, efficiency, and applicability across diverse infrastructure monitoring scenarios.

This research demonstrates that deep learning-based classification, leveraging transfer learning from large-scale pre-trained models, provides an effective and practical solution for automated corrosion severity assessment in steel infrastructure. By providing evidence-based architecture comparison, deployment guidelines, and quantified performance metrics, this work advances the state of automated infrastructure inspection and provides practitioners with actionable guidance for implementing automated assessment systems that improve structural safety, reduce maintenance costs, and enable data-driven infrastructure management.

% ========================================
% ACKNOWLEDGMENTS
% ========================================
\section*{Acknowledgments}
The authors acknowledge the Catholic University of Petr\'opolis (UCP) for providing the computational resources and infrastructure necessary for this research.

% ========================================
% REFERENCES
% ========================================
\bibliographystyle{ascelike-new}
\bibliography{referencias_pure_classification}


\section{Data Availability Statement}

The code for model training, evaluation, and figure generation is publicly available at: \url{https://github.com/[USERNAME]/corrosion-classification}

The trained model weights are available upon reasonable request to the corresponding author. The dataset cannot be publicly shared due to proprietary restrictions.

\textbf{Reproducibility:} All experiments used random seed 42 for reproducibility. Software versions: Python 3.12, TensorFlow 2.20.0, NumPy 2.2.6, scikit-learn 1.7.2.

\end{document}
